import streamlit as st
import os
import google.generativeai as genai

from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter


# -----------------------------------------------------------
# API KEY
# -----------------------------------------------------------

try:
    GEMINI_KEY = st.secrets["GEMINI_API_KEY"]
except:
    GEMINI_KEY = os.getenv("GEMINI_API_KEY")

if GEMINI_KEY is None:
    st.error("GEMINI_API_KEY bulunamadÄ±. LÃ¼tfen ortam deÄŸiÅŸkenini tanÄ±mla.")
    st.stop()

genai.configure(api_key=GEMINI_KEY)
model = genai.GenerativeModel("models/gemini-2.5-flash")



# -----------------------------------------------------------
# EMBEDDING MODEL
# -----------------------------------------------------------

embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")


# -----------------------------------------------------------
# CHROMA DB & PDF
# -----------------------------------------------------------

CHROMA_DB_PATH = "./chroma_db_cv"
PDF_PATH = "YOUR-CV"

if not os.path.exists(CHROMA_DB_PATH):
    st.info("CV vektÃ¶r veritabanÄ± oluÅŸturuluyor...")

    loader = PyPDFLoader(PDF_PATH)
    documents = loader.load()

    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = splitter.split_documents(documents)

    vector_store = Chroma.from_documents(
        documents=splits,
        embedding=embeddings,
        persist_directory=CHROMA_DB_PATH
    )

    st.success("CV baÅŸarÄ±yla indexlendi âœ…")
else:
    vector_store = Chroma(
        embedding_function=embeddings,
        persist_directory=CHROMA_DB_PATH
    )


retriever = vector_store.as_retriever(search_kwargs={"k": 3})


# -----------------------------------------------------------
# PROMPT
# -----------------------------------------------------------

"""
Kendinize gÃ¶re aÅŸaÄŸÄ±yÄ± gÃ¼ncelleyiniz.

"""
PROMPT_TEMPLATE = """
Sen Alican TunÃ§'un kiÅŸisel AI asistansÄ±n.

GÃ–REV:
KullanÄ±cÄ±ya sadece Alican TunÃ§'un CV bilgilerine dayanarak cevap ver.

KURALLAR:
- Sadece verilen CV iÃ§eriÄŸini kullan.
- Tahmin etme veya uydurma.
- EÄŸer cevap CV'de yoksa, aynen ÅŸunu sÃ¶yle:
  "Bu bilgi CV'de yer almÄ±yor."

TON:
- Profesyonel
- KÄ±sa ve net

CV Ä°Ã‡ERÄ°ÄÄ°:
{context}

KULLANICI SORUSU:
{question}

CEVAP:
"""


# -----------------------------------------------------------
# RAG PIPELINE
# -----------------------------------------------------------

def call_gemini(prompt: str) -> str:
    response = model.generate_content(prompt)
    return response.text


def run_rag(question: str) -> str:
    docs = vector_store.similarity_search(question, k=3)
    context = "\n\n".join([doc.page_content for doc in docs])

    final_prompt = PROMPT_TEMPLATE.format(
        context=context,
        question=question
    )

    return call_gemini(final_prompt)



# -----------------------------------------------------------
# STREAMLIT UI
# -----------------------------------------------------------

"""
Kendinize gÃ¶re aÅŸaÄŸÄ±yÄ± gÃ¼ncelleyiniz.

"""


st.title("ğŸ¤– Alican TunÃ§ - AI CV AsistanÄ±")
st.write("CV'me ve projelerime dayanarak bana her ÅŸeyi sorabilirsin.")

query = st.text_input("Alican hakkÄ±nda ne Ã¶ÄŸrenmek istiyorsun?")


if query:
    with st.spinner("CV iÃ§inde aranÄ±yor..."):
        response = run_rag(query)
        st.success("AI YanÄ±tÄ±")
        st.info(response)
